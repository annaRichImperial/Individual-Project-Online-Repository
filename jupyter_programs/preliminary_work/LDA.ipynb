{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#working version is on pycharm on university computer\n",
    "#on university computer it computes 5 topics for all conflated\n",
    "#also computes 5 topics PER speech\n",
    "#results are in the \"summaries\" directory \n",
    "#topics it gives are the areas of text to focus on (perhaps)\n",
    "\n",
    "from __future__ import unicode_literals\n",
    "from spacy.lang.en import English\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from gensim import corpora\n",
    "import os\n",
    "import gensim\n",
    "import pickle\n",
    "import spacy\n",
    "import nltk\n",
    "import codecs\n",
    "\n",
    "spacy.load('en')\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    parser = English()\n",
    "    lda_tokens = []\n",
    "    tokens = parser(text)\n",
    "    for token in tokens:\n",
    "        if token.orth_.isspace():\n",
    "            continue\n",
    "        elif token.like_url:\n",
    "            lda_tokens.append('URL')\n",
    "        elif token.orth_.startswith('@'):\n",
    "            lda_tokens.append('SCREEN_NAME')\n",
    "        else:\n",
    "            lda_tokens.append(token.lower_)\n",
    "    return lda_tokens\n",
    "\n",
    "\n",
    "def get_lemma(word):\n",
    "    lemma = wn.morphy(word)\n",
    "    if lemma is None:\n",
    "        return word\n",
    "    else:\n",
    "        return lemma\n",
    "\n",
    "\n",
    "def get_lemma2(word):\n",
    "    return WordNetLemmatizer().lemmatize(word)\n",
    "\n",
    "\n",
    "def prepare_text_for_lda(text):\n",
    "    en_stop = set(nltk.corpus.stopwords.words('english'))\n",
    "    tokens = tokenize(text)\n",
    "    tokens = [token for token in tokens if len(token) > 4]\n",
    "    tokens = [token for token in tokens if token not in en_stop]\n",
    "    tokens = [get_lemma(token) for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def main():\n",
    "    nltk.download('wordnet')\n",
    "    nltk.download('stopwords')\n",
    "    text_data = []\n",
    "\n",
    "    directory = '/homes/ahr18/PycharmProjects/topic_practice/Source/data'\n",
    "\n",
    "    os.chdir(directory)\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            print(filename)\n",
    "            f = open(filename)\n",
    "            #lines = f.read()\n",
    "            with codecs.open(filename, 'r', encoding='utf-8') as fg:\n",
    "                for line in fg:\n",
    "                    tokens = prepare_text_for_lda(line)\n",
    "                    text_data.append(tokens)\n",
    "\n",
    "    dictionary = corpora.Dictionary(text_data)\n",
    "    corpus = [dictionary.doc2bow(text) for text in text_data]\n",
    "\n",
    "    pickle.dump(corpus, open('corpus.pkl', 'wb'))\n",
    "    dictionary.save('dictionary.gensim')\n",
    "\n",
    "    ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=5, id2word=dictionary, passes=15)\n",
    "    ldamodel.save('model5.gensim')\n",
    "    topics = ldamodel.print_topics(num_words=4)\n",
    "\n",
    "    for topic in topics:\n",
    "        print(topic)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
