{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  3692\n",
      "Total Vocab:  33\n",
      "Total Patterns:  3592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0720 13:48:24.319549 11536 deprecation.py:323] From C:\\Users\\annah\\Anaconda4\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3592/3592 [==============================] - 56s 16ms/step - loss: 3.0856\n",
      "\n",
      "Epoch 00001: loss improved from inf to 3.08564, saving model to weights-improvement-01-3.0856.hdf5\n",
      "Epoch 2/20\n",
      "3592/3592 [==============================] - 46s 13ms/step - loss: 2.9586\n",
      "\n",
      "Epoch 00002: loss improved from 3.08564 to 2.95858, saving model to weights-improvement-02-2.9586.hdf5\n",
      "Epoch 3/20\n",
      "3592/3592 [==============================] - 46s 13ms/step - loss: 2.9522\n",
      "\n",
      "Epoch 00003: loss improved from 2.95858 to 2.95217, saving model to weights-improvement-03-2.9522.hdf5\n",
      "Epoch 4/20\n",
      "3592/3592 [==============================] - 41s 12ms/step - loss: 2.9474\n",
      "\n",
      "Epoch 00004: loss improved from 2.95217 to 2.94737, saving model to weights-improvement-04-2.9474.hdf5\n",
      "Epoch 5/20\n",
      "3592/3592 [==============================] - 48s 13ms/step - loss: 2.9437\n",
      "\n",
      "Epoch 00005: loss improved from 2.94737 to 2.94366, saving model to weights-improvement-05-2.9437.hdf5\n",
      "Epoch 6/20\n",
      "3592/3592 [==============================] - 48s 13ms/step - loss: 2.9406\n",
      "\n",
      "Epoch 00006: loss improved from 2.94366 to 2.94056, saving model to weights-improvement-06-2.9406.hdf5\n",
      "Epoch 7/20\n",
      "3592/3592 [==============================] - 45s 13ms/step - loss: 2.9371\n",
      "\n",
      "Epoch 00007: loss improved from 2.94056 to 2.93715, saving model to weights-improvement-07-2.9371.hdf5\n",
      "Epoch 8/20\n",
      "3592/3592 [==============================] - 53s 15ms/step - loss: 2.9349\n",
      "\n",
      "Epoch 00008: loss improved from 2.93715 to 2.93485, saving model to weights-improvement-08-2.9349.hdf5\n",
      "Epoch 9/20\n",
      "3592/3592 [==============================] - 43s 12ms/step - loss: 2.9366\n",
      "\n",
      "Epoch 00009: loss did not improve from 2.93485\n",
      "Epoch 10/20\n",
      "3592/3592 [==============================] - 39s 11ms/step - loss: 2.9349\n",
      "\n",
      "Epoch 00010: loss did not improve from 2.93485\n",
      "Epoch 11/20\n",
      "3592/3592 [==============================] - 38s 11ms/step - loss: 2.9363\n",
      "\n",
      "Epoch 00011: loss did not improve from 2.93485\n",
      "Epoch 12/20\n",
      "3592/3592 [==============================] - 40s 11ms/step - loss: 2.9323\n",
      "\n",
      "Epoch 00012: loss improved from 2.93485 to 2.93234, saving model to weights-improvement-12-2.9323.hdf5\n",
      "Epoch 13/20\n",
      "3592/3592 [==============================] - 37s 10ms/step - loss: 2.9277\n",
      "\n",
      "Epoch 00013: loss improved from 2.93234 to 2.92765, saving model to weights-improvement-13-2.9277.hdf5\n",
      "Epoch 14/20\n",
      "3592/3592 [==============================] - 38s 11ms/step - loss: 2.9243\n",
      "\n",
      "Epoch 00014: loss improved from 2.92765 to 2.92433, saving model to weights-improvement-14-2.9243.hdf5\n",
      "Epoch 15/20\n",
      "3592/3592 [==============================] - 38s 11ms/step - loss: 2.9161\n",
      "\n",
      "Epoch 00015: loss improved from 2.92433 to 2.91612, saving model to weights-improvement-15-2.9161.hdf5\n",
      "Epoch 16/20\n",
      "3592/3592 [==============================] - 40s 11ms/step - loss: 2.9104\n",
      "\n",
      "Epoch 00016: loss improved from 2.91612 to 2.91044, saving model to weights-improvement-16-2.9104.hdf5\n",
      "Epoch 17/20\n",
      "3592/3592 [==============================] - 39s 11ms/step - loss: 2.9048\n",
      "\n",
      "Epoch 00017: loss improved from 2.91044 to 2.90478, saving model to weights-improvement-17-2.9048.hdf5\n",
      "Epoch 18/20\n",
      "3592/3592 [==============================] - 44s 12ms/step - loss: 2.8866\n",
      "\n",
      "Epoch 00018: loss improved from 2.90478 to 2.88660, saving model to weights-improvement-18-2.8866.hdf5\n",
      "Epoch 19/20\n",
      "3592/3592 [==============================] - 36s 10ms/step - loss: 2.8795\n",
      "\n",
      "Epoch 00019: loss improved from 2.88660 to 2.87951, saving model to weights-improvement-19-2.8795.hdf5\n",
      "Epoch 20/20\n",
      "3592/3592 [==============================] - 35s 10ms/step - loss: 2.8626\n",
      "\n",
      "Epoch 00020: loss improved from 2.87951 to 2.86264, saving model to weights-improvement-20-2.8626.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x163c6bcafd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Small LSTM Network to Generate Text for Alice in Wonderland\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "# load ascii text and covert to lowercase\n",
    "filename = \"data\\\\1952.txt\"\n",
    "raw_text = open(filename).read()\n",
    "raw_text = raw_text.lower()\n",
    "# create mapping of unique chars to integers\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "# summarize the loaded data\n",
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print (\"Total Characters: \", n_chars)\n",
    "print (\"Total Vocab: \", n_vocab)\n",
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    seq_in = raw_text[i:i + seq_length]\n",
    "    seq_out = raw_text[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print (\"Total Patterns: \", n_patterns)\n",
    "# reshape X to be [samples, time steps, features]\n",
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)\n",
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "# define the checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "# fit the model\n",
    "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
